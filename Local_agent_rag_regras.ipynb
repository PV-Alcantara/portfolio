{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7d74ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bibliotecas do agente \n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.agents import initialize_agent, AgentType, AgentExecutor # Usado para os sub-agentes\n",
    "from langchain_core.tools import StructuredTool # Para ferramentas com schema\n",
    "from langchain.memory import ConversationBufferMemory, ConversationBufferWindowMemory # Importação da memória / definição de contexto para armazenamento da memória\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder # Para o agente principal\n",
    "from pydantic import BaseModel, Field # Necessário para StructuredTool\n",
    "from langchain_core.messages import HumanMessage, AIMessage \n",
    "\n",
    "\n",
    "#Funções diversas em Python\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "#importações para RAG\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_chroma import Chroma #banco vetorial\n",
    "import shutil \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7def8e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Documentos carregados. Número de documentos: 1\n",
      "DEBUG: Número de chunks criados: 4\n",
      "DEBUG: Primeiro chunk: 1) REGRAS DE SINTAXE \n",
      " **NÃO INCLUA ASPAS TRIPLAS (```) OU QUALQUER OUTRO DELIMITADOR DE CÓDIGO NO A...\n"
     ]
    }
   ],
   "source": [
    "#1) Criação da pasta onde estão as informações\n",
    "docs_folder = \"docs\"\n",
    "csv_file_path = os.path.join(docs_folder, \"dataset.csv\")\n",
    "txt_file_path = os.path.join(docs_folder, \"regras.txt\")\n",
    "\n",
    "#carregar os documentos\n",
    "loader = TextLoader(txt_file_path, encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "print(f\"DEBUG: Documentos carregados. Número de documentos: {len(documents)}\")\n",
    "\n",
    "# Dividir documentos em chunks (pedaços menores)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(documents)\n",
    "print(f\"DEBUG: Número de chunks criados: {len(splits)}\")\n",
    "print(f\"DEBUG: Primeiro chunk: {splits[0].page_content[:100]}...\")\n",
    "\n",
    "embeddings_model = 'nomic-embed-text'\n",
    "embeddings = OllamaEmbeddings(model=embeddings_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa45df8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Removendo diretório existente do ChromaDB para forçar atualização: './chroma_db_agente_local'\n",
      "DEBUG: Diretório do ChromaDB removido com sucesso.\n",
      "DEBUG: Criando e preenchendo novo ChromaDB com documentos atualizados...\n",
      "DEBUG: Novo ChromaDB criado e preenchido com sucesso com dados atualizados!\n",
      "\n",
      "DEBUG: Número de chunks originais (splits): 4\n",
      "DEBUG: Número de documentos no ChromaDB: 4\n",
      "DEBUG: A contagem de documentos no ChromaDB corresponde ao número de splits.\n"
     ]
    }
   ],
   "source": [
    "# 2) Criação ou Carregamento do banco vetorial em chroma_db\n",
    "# Definindo um caminho de pasta específico para este projeto\n",
    "chroma_db_path = \"./chroma_db_agente_local\" \n",
    "vectorstore = None # Inicializa o vectorstore como None\n",
    "\n",
    "if os.path.exists(chroma_db_path):\n",
    "    print(f\"DEBUG: Removendo diretório existente do ChromaDB para forçar atualização: '{chroma_db_path}'\")\n",
    "    shutil.rmtree(chroma_db_path)\n",
    "    print(\"DEBUG: Diretório do ChromaDB removido com sucesso.\")\n",
    "\n",
    "print(\"DEBUG: Criando e preenchendo novo ChromaDB com documentos atualizados...\")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=chroma_db_path\n",
    ")\n",
    "print(\"DEBUG: Novo ChromaDB criado e preenchido com sucesso com dados atualizados!\")\n",
    "\n",
    "# teste. Contagem de Documentos\n",
    "print(f\"\\nDEBUG: Número de chunks originais (splits): {len(splits)}\")\n",
    "try:\n",
    "    chroma_collection = vectorstore._collection\n",
    "    count_in_db = chroma_collection.count()\n",
    "    print(f\"DEBUG: Número de documentos no ChromaDB: {count_in_db}\")\n",
    "\n",
    "    if count_in_db == len(splits):\n",
    "        print(\"DEBUG: A contagem de documentos no ChromaDB corresponde ao número de splits.\")\n",
    "    else:\n",
    "        print(\"ALERTA: A contagem de documentos no ChromaDB NÃO corresponde ao número de splits. Pode haver um problema.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERRO: Não foi possível contar documentos no ChromaDB: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97944064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Dataset CSV carregado em DataFrame. Linhas: 765\n"
     ]
    }
   ],
   "source": [
    "#3) Criação de funções\n",
    "\n",
    "#criação do dataset\n",
    "df_info_dataset = None\n",
    "try:\n",
    "    df_info_dataset = pd.read_csv(csv_file_path)\n",
    "    print(f\"DEBUG: Dataset CSV carregado em DataFrame. Linhas: {len(df_info_dataset)}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO: O arquivo '{csv_file_path}' não foi encontrado.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERRO: Não foi possível carregar o CSV para DataFrame: {e}\")\n",
    "\n",
    "\n",
    "def buscar_documentos (query: str) -> str:\n",
    "    \"\"\"**PRIMEIRA ETAPA SEMPRE**\n",
    "    utilize essa ferramenta sempre no inicio da query para interpretar e entender as regras de negócio da pergunta do usuário.\n",
    "    essa ferramenta aceita a query em linguagem natural.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    retriever = vectorstore.as_retriever()\n",
    "    docs = retriever.invoke(query)\n",
    "    if docs:\n",
    "        return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    else:\n",
    "        return \"Não encontrei informações relevantes nos documentos para esta consulta.\"\n",
    "    \n",
    "def sql_documentos (query_sql: str) -> str:\n",
    "    \"\"\"\n",
    "    ** SEGUNDA ETAPA SEMPRE**\n",
    "    Use esta ferramenta para **consultas quantitativas/qualitativas** dentro do dataset chamado 'df_info_dataset'\n",
    "    Esta ferramenta exige uma query onde o 'from' deve ser sempre 'df_info_dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    global df_info_dataset # Permite que a função acesse o df_data global\n",
    "    if df_info_dataset is None:\n",
    "        return \"Erro: O DataFrame 'df_info_dataset' não foi carregado. Não é possível executar consultas SQL.\"\n",
    "\n",
    "    colunas_originais = df_info_dataset.columns.tolist()\n",
    "    \n",
    "    # Cria dicionário de mapeamento simples\n",
    "    mapeamento = {}\n",
    "    for col in colunas_originais:\n",
    "        col_nova = col.upper()\n",
    "        col_nova = re.sub(r\"[^A-Z0-9]\", \"_\", col_nova)  # Substitui espaços/símbolos por _\n",
    "        col_nova = re.sub(r\"_+\", \"_\", col_nova).strip(\"_\")  # Remove múltiplos _\n",
    "        mapeamento[col] = col_nova\n",
    "\n",
    "    # Aplica o mapeamento\n",
    "    df_info_dataset.columns = [mapeamento[col] for col in df_info_dataset.columns]\n",
    "    \n",
    "\n",
    "    result = sqldf(query_sql, {'df_info_dataset': df_info_dataset}) # Mapeamento do dataset para o agente\n",
    "\n",
    "   \n",
    "    if not result.empty and len(result.columns) == 1 and len(result) == 1:\n",
    "        return str(result.iloc[0, 0]) # Retorna o valor da única célula como string\n",
    "    else:\n",
    "        return result.to_string(index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6866b558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4) Criação de Schema\n",
    "class buscar_documentos_input(BaseModel):\n",
    "    query: str = Field(description=\"Consulta na documentaçao.\")\n",
    "\n",
    "class sql_documentos_input(BaseModel):\n",
    "    query_sql: str = Field(description=\"Consulta SQL no dataset df_info_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "828cb531",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5) Criação das ferramentas estruturadas\n",
    "buscar_tool = StructuredTool.from_function(\n",
    "    func=buscar_documentos,\n",
    "    name='buscar_documentos',\n",
    "    description=buscar_documentos.__doc__.strip(),\n",
    "    args_schema=buscar_documentos_input\n",
    ")\n",
    "\n",
    "query_tool = StructuredTool.from_function(\n",
    "    func=sql_documentos,\n",
    "    name='sql_documentos',\n",
    "    description=sql_documentos.__doc__.strip(),\n",
    "    args_schema=sql_documentos_input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d622973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pichau\\AppData\\Local\\Temp\\ipykernel_11716\\2064540434.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  main_memory = ConversationBufferWindowMemory(\n"
     ]
    }
   ],
   "source": [
    "#6) Criação da memória dos agentes\n",
    "main_memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    k=5 # Mantenha as últimas 5 interações (5 pares de HumanMessage/AIMessage)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e0c9da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Agente configurado com sucesso para LLM local.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pichau\\AppData\\Local\\Temp\\ipykernel_11716\\1699356882.py:7: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent_executor = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "#7) Criação do Agente\n",
    "llm = OllamaLLM(model=\"qwen3\",\n",
    "                temperature=0.15,\n",
    "                max_tokens=500              \n",
    "                )\n",
    "\n",
    "agent_executor = initialize_agent(\n",
    "    tools=[query_tool, buscar_tool],\n",
    "    llm=llm,\n",
    "    agent_type=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    memory=main_memory, # Adicionando memória\n",
    "    agent_kwargs={\"system_message\": \"\"\"Você é um analista de dados focado em trazer os resultados de projetos.\n",
    "    Sempre utilize as ferramentas disponíveis para responder às perguntas do usuário.\n",
    "\n",
    "    **IMPORTANTE: Seu processo de pensamento deve seguir o formato ReAct (Thought, Action, Action Input, Observation, Thought, Final Answer).**\n",
    "\n",
    "    **Regras de Uso das Ferramentas:**\n",
    "                                \n",
    "    1.  SEMPRE SIGA O SEGUINTE FLUXO: I. buscar_tool (para entendimento das regras de negócio) -> II. query_tool (para confecçao da query quantitativa/qualitativa),\n",
    "                        \n",
    "        **Para perguntas de caráter quantitativo ou qualitativo que exigem análise de dados tabulares, agregação (COUNT, SUM, AVG), filtragem precisa ou qualquer cálculo sobre o dataset, VOCÊ DEVE usar a ferramenta 'query_tool'. Lembre-se que o nome da tabela no SQL é 'df_info_dataset'.**\n",
    "        * Ao usar a 'query_tool', o **Action Input DEVE CONTER APENAS a string SQL pura e NADA MAIS**.\n",
    "        * **NÃO INCLUA ASPAS TRIPLAS (```) OU QUALQUER OUTRO DELIMITADOR DE CÓDIGO NO Action Input para 'query_tool'.**\n",
    "        * **EXEMPLO CERTO:** Action Input: SELECT MARCA, SUM(CPV_UND) FROM df_info_dataset GROUP BY MARCA\n",
    "        * **EXEMPLO ERRADO:** Action Input: ```SELECT MARCA, SUM(CPV_UND) FROM df_info_dataset GROUP BY MARCA```\n",
    "                  \n",
    "        **Regras Específicas para Filtros de Data:**\n",
    "        * Ao filtrar por datas, **SEMPRE** utilize o formato `WHERE DATA >= 'YYYY-MM-DD' AND DATA <= 'YYYY-MM-DD'`.\n",
    "        * **NUNCA** utilize funções como `year(DATA) = YYYY` ou `month(DATA) = MM` ou qualquer outro método que não seja a comparação direta de datas no formato 'YYYY-MM-DD'.\n",
    "        * **EXEMPLO CERTO DE FILTRO DE DATA:** `WHERE DATA >='2025-05-01' AND DATA <= '2024-05-31'` \n",
    "        * **EXEMPLO ERRADO DE FILTRO DE DATA:** `WHERE year(DATA) = 2024 AND month(DATA) = 5`\n",
    "                   \n",
    "        * Exemplo de Thought para esta ferramenta: \"A pergunta é quantitativa, preciso usar query_tool para contar as marcas.\"\n",
    "        * Exemplo de Final Answer após usar esta ferramenta: \"Existem X marcas no dataset.\"\n",
    "                            \n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    ")\n",
    "print(\"DEBUG: Agente configurado com sucesso para LLM local.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5de7357c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Teste 1: Pergunta 1 ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m<think>\n",
      "Okay, the user is asking how many brands exist in the file. First, I need to figure out the correct approach. The tools available are 'buscar_documentos' and 'sql_documentos'. According to the instructions, 'buscar_documentos' should be used first to understand the business rules or structure of the data. So I'll start by using that tool to get an overview of the dataset.\n",
      "\n",
      "I'll input a general query to 'buscar_documentos' to see what the dataset contains. Maybe the user is referring to a specific column like 'Marca' or 'Brand'. Once I understand the structure, I can then use 'sql_documentos' to count the distinct brands.\n",
      "\n",
      "Wait, the user's question is straightforward: count the number of brands. But I need to make sure which column represents the brand. Let me first use 'buscar_documentos' to get information about the dataset's columns and possible entries. That way, I can identify the correct column to count distinct values from.\n",
      "</think>\n",
      "\n",
      "Thought: Preciso primeiro entender a estrutura do dataset para identificar qual coluna representa as marcas.\n",
      "Action: buscar_documentos\n",
      "Action Input: \"Quais são as colunas e os dados presentes no dataset?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m**Sinônimos e Definições Adicionais:**\n",
      "* Marca pode ser também 'Produto'.\n",
      "* Data pode ser também 'Período, Data ou Ocorrência'.\n",
      "* Apresentacao pode ser também 'SKU'.\n",
      "* EAN pode ser também 'Código'.\n",
      "* CPV_UND pode ser também 'UNIDADES CPV','CPV_UNIDADES','UND_CAMPANHA','UNIDADES CAMPANHA','UNIDADES VENDIDAS'.\n",
      "* MDTR_UND pode ser também 'UNIDADES MDTR', 'MDTR_UNIDADES', 'MDTR'.\n",
      "\n",
      "* Caso o usuário já traga o nome da Marca, não se esqueça de adicionar o sulfixo ' (A4H)' caso ele não tenha escrito.\n",
      "\n",
      "**EXEMPLO_3 CONVERSÃO, o usuário pode pedir a conversão de algum produto, esta regra consiste na soma de CPV_UND dividido pela soma de MDTR_UND, deve-se seguir o exemplo da estrutura abaixo e alterando as variáveis conforme necessidade:\n",
      "select sum(CPV_UND) / sum(MDTR_UND)\n",
      "from df_info_dataset\n",
      "group by Marca\n",
      "\n",
      "**EXEMPLO_4 TOTAL DE MARCAS, o usuário pode pedir o total de marcas distintas de algum produto, esta regra consiste na contagem distinta das marcas , deve-se seguir o exemplo da estrutura abaixo e alterando as variáveis conforme necessidade:\n",
      "select count(distinct(Marca))\n",
      "from df_info_dataset\n",
      "group by Marca\n",
      "\n",
      "\n",
      "3) ESTRUTURA DO DATASET, TERMOS & SINÔNIMOS do dataset 'df_info_dataset':\n",
      "* 'DATA': Tipo data (yyyy-mm-dd).\n",
      "* 'MARCA': Tipo texto (ex: 'LUTEAL (A4H)').\n",
      "* 'APRESENTACAO': Tipo texto (ex: 'LUTEAL CAP MOLE BLX60').\n",
      "* 'EAN': Tipo texto/numérico (código, ex: '7896658040894').\n",
      "* 'MDTR_UND': Tipo numérico (Unidades de MDTR).\n",
      "* 'CPV_UND': Tipo numérico (Unidades de CPV).\n",
      "\n",
      "1) REGRAS DE SINTAXE \n",
      " **NÃO INCLUA ASPAS TRIPLAS (```) OU QUALQUER OUTRO DELIMITADOR DE CÓDIGO NO Action Input para 'query_tool'.**\n",
      " **EXEMPLO CERTO:** Action Input: SELECT MARCA, SUM(CPV_UND) FROM df_info_dataset GROUP BY MARCA\n",
      " **EXEMPLO ERRADO:** Action Input: ```SELECT MARCA, SUM(CPV_UND) FROM df_info_dataset GROUP BY MARCA```\n",
      "                  \n",
      " **Regras Específicas para Filtros de Data:**\n",
      " * Ao filtrar por datas, **SEMPRE** utilize o formato `WHERE DATA >= 'YYYY-MM-DD' AND DATA <= 'YYYY-MM-DD'`.\n",
      " * **NUNCA** utilize funções como `year(DATA) = YYYY` ou `month(DATA) = MM` ou qualquer outro método que não seja a comparação direta de datas no formato 'YYYY-MM-DD'.\n",
      " * **EXEMPLO CERTO DE FILTRO DE DATA:** `WHERE DATA >='2025-05-01' AND DATA <= '2024-05-31'` \n",
      "\n",
      " * **EXEMPLO ERRADO DE FILTRO DE DATA:** `WHERE year(DATA) = 2024 AND month(DATA) = 5`\n",
      "\n",
      "* **EXEMPLO ERRADO DE FILTRO DE DATA:** `WHERE year(DATA) = 2024 AND month(DATA) = 5`\n",
      "\n",
      "\n",
      "2) REGRAS DE NEGOCIO\n",
      "**EXEMPLO_1 SOMA, o usuário pode pedir o valor total de uma marca então deve-se utilizar a ferramenta adequada para query, seguindo o exemplo da estrutura abaixo e alterando as variáveis conforme necessidade:\n",
      "select sum(CPV_UND) \n",
      "from df_info_dataset\n",
      "where Marca = 'MOTORE (A4H)'\n",
      "\n",
      "**EXEMPLO_2 MÉDIA, o usuário pode pedir a média de  períodos então deve-se utilizar a ferramenta adequada para query, seguindo o exemplo da estrutura abaixo e alterando as variáveis conforme necessidade:\n",
      "select avg(CPV_UND) \n",
      "from df_info_dataset\n",
      "where Data >= '2024-01-01' and Data <= '2024-12-31' and Marca = 'ALENIA (A4H)'\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m<think>\n",
      "Okay, the user is asking how many brands exist in the file. From the previous observation, I see that the dataset 'df_info_dataset' has a column named 'MARCA' which likely represents the brand. The user wants the count of distinct brands. \n",
      "\n",
      "First, I need to confirm that 'MARCA' is the correct column for brands. The initial response from 'buscar_documentos' mentioned that 'Marca' can also be referred to as 'Produto', but in the dataset structure, it's listed as 'MARCA'. So, I'll use 'MARCA' as the column name.\n",
      "\n",
      "Next, I should use the 'sql_documentos' tool to execute a SQL query that counts the distinct values in the 'MARCA' column. The correct SQL query would be:\n",
      "\n",
      "SELECT COUNT(DISTINCT MARCA) FROM df_info_dataset;\n",
      "\n",
      "This query will return the number of unique brands in the dataset. I need to make sure that the 'from' clause is correctly set to 'df_info_dataset' as required by the tool. \n",
      "\n",
      "Since the user's question is straightforward and the necessary information is available, I can proceed to execute this SQL query using the 'sql_documentos' tool. The result will give the exact number of brands, which I can then present as the final answer.\n",
      "</think>\n",
      "\n",
      "Thought: Agora que sei que a coluna \"MARCA\" representa as marcas, posso usar a ferramenta sql_documentos para contar as marcas distintas.\n",
      "Action: sql_documentos\n",
      "Action Input: SELECT COUNT(DISTINCT MARCA) FROM df_info_dataset\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m35\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m<think>\n",
      "</think>\n",
      "\n",
      "Final Answer: Existem 35 marcas no arquivo.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Resposta: Existem 35 marcas no arquivo.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 8) Testando o agente\n",
    "chat_history = []\n",
    "\n",
    "print(\"\\n--- Teste 1: Pergunta 1 ---\")\n",
    "user_input_1 = \"Quantas Marcas existem neste arquivo?\"\n",
    "response_1 = agent_executor.invoke({\"input\": user_input_1, \"chat_history\": chat_history})\n",
    "chat_history.extend([HumanMessage(content=user_input_1), AIMessage(content=response_1[\"output\"])])\n",
    "print(f\"Resposta: {response_1['output']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bd5808b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Teste 2: Pergunta de cálculo ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m<think>\n",
      "Okay, let's tackle this question. The user wants to know which brand sold the most units, considering the total units sold. The dataset is called 'df_info_dataset'. \n",
      "\n",
      "First, I need to understand the structure of the dataset. Since the user mentioned \"unidades CPV\", I should check what columns are present. The 'buscar_documentos' tool can help me get an overview. I'll start by using that tool to understand the data.\n",
      "\n",
      "Action: buscar_documentos\n",
      "Action Input: \"Quais são as colunas do df_info_dataset e seus tipos de dados?\"\n",
      "\n",
      "After getting the columns, I can proceed to write a SQL query. Assuming there's a 'marca' (brand) column and a 'unidades_vendidas' (units sold) column, I need to sum the units per brand and find the maximum. \n",
      "\n",
      "Once I have the SQL query result, I can determine the brand with the highest total units. If there's a tie, I might need to handle that, but the question probably expects a single answer. \n",
      "\n",
      "So, the steps are: first, understand the data structure, then write the SQL query to aggregate and find the maximum.\n",
      "</think>\n",
      "\n",
      "Thought: Preciso entender a estrutura do dataset para identificar as colunas relevantes (marca e unidades vendidas). \n",
      "Action: buscar_documentos\n",
      "Action Input: \"Quais são as colunas do df_info_dataset e seus tipos de dados?\"\n",
      "\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m1) REGRAS DE SINTAXE \n",
      " **NÃO INCLUA ASPAS TRIPLAS (```) OU QUALQUER OUTRO DELIMITADOR DE CÓDIGO NO Action Input para 'query_tool'.**\n",
      " **EXEMPLO CERTO:** Action Input: SELECT MARCA, SUM(CPV_UND) FROM df_info_dataset GROUP BY MARCA\n",
      " **EXEMPLO ERRADO:** Action Input: ```SELECT MARCA, SUM(CPV_UND) FROM df_info_dataset GROUP BY MARCA```\n",
      "                  \n",
      " **Regras Específicas para Filtros de Data:**\n",
      " * Ao filtrar por datas, **SEMPRE** utilize o formato `WHERE DATA >= 'YYYY-MM-DD' AND DATA <= 'YYYY-MM-DD'`.\n",
      " * **NUNCA** utilize funções como `year(DATA) = YYYY` ou `month(DATA) = MM` ou qualquer outro método que não seja a comparação direta de datas no formato 'YYYY-MM-DD'.\n",
      " * **EXEMPLO CERTO DE FILTRO DE DATA:** `WHERE DATA >='2025-05-01' AND DATA <= '2024-05-31'` \n",
      "\n",
      " * **EXEMPLO ERRADO DE FILTRO DE DATA:** `WHERE year(DATA) = 2024 AND month(DATA) = 5`\n",
      "\n",
      "**EXEMPLO_3 CONVERSÃO, o usuário pode pedir a conversão de algum produto, esta regra consiste na soma de CPV_UND dividido pela soma de MDTR_UND, deve-se seguir o exemplo da estrutura abaixo e alterando as variáveis conforme necessidade:\n",
      "select sum(CPV_UND) / sum(MDTR_UND)\n",
      "from df_info_dataset\n",
      "group by Marca\n",
      "\n",
      "**EXEMPLO_4 TOTAL DE MARCAS, o usuário pode pedir o total de marcas distintas de algum produto, esta regra consiste na contagem distinta das marcas , deve-se seguir o exemplo da estrutura abaixo e alterando as variáveis conforme necessidade:\n",
      "select count(distinct(Marca))\n",
      "from df_info_dataset\n",
      "group by Marca\n",
      "\n",
      "\n",
      "3) ESTRUTURA DO DATASET, TERMOS & SINÔNIMOS do dataset 'df_info_dataset':\n",
      "* 'DATA': Tipo data (yyyy-mm-dd).\n",
      "* 'MARCA': Tipo texto (ex: 'LUTEAL (A4H)').\n",
      "* 'APRESENTACAO': Tipo texto (ex: 'LUTEAL CAP MOLE BLX60').\n",
      "* 'EAN': Tipo texto/numérico (código, ex: '7896658040894').\n",
      "* 'MDTR_UND': Tipo numérico (Unidades de MDTR).\n",
      "* 'CPV_UND': Tipo numérico (Unidades de CPV).\n",
      "\n",
      "* **EXEMPLO ERRADO DE FILTRO DE DATA:** `WHERE year(DATA) = 2024 AND month(DATA) = 5`\n",
      "\n",
      "\n",
      "2) REGRAS DE NEGOCIO\n",
      "**EXEMPLO_1 SOMA, o usuário pode pedir o valor total de uma marca então deve-se utilizar a ferramenta adequada para query, seguindo o exemplo da estrutura abaixo e alterando as variáveis conforme necessidade:\n",
      "select sum(CPV_UND) \n",
      "from df_info_dataset\n",
      "where Marca = 'MOTORE (A4H)'\n",
      "\n",
      "**EXEMPLO_2 MÉDIA, o usuário pode pedir a média de  períodos então deve-se utilizar a ferramenta adequada para query, seguindo o exemplo da estrutura abaixo e alterando as variáveis conforme necessidade:\n",
      "select avg(CPV_UND) \n",
      "from df_info_dataset\n",
      "where Data >= '2024-01-01' and Data <= '2024-12-31' and Marca = 'ALENIA (A4H)'\n",
      "\n",
      "**Sinônimos e Definições Adicionais:**\n",
      "* Marca pode ser também 'Produto'.\n",
      "* Data pode ser também 'Período, Data ou Ocorrência'.\n",
      "* Apresentacao pode ser também 'SKU'.\n",
      "* EAN pode ser também 'Código'.\n",
      "* CPV_UND pode ser também 'UNIDADES CPV','CPV_UNIDADES','UND_CAMPANHA','UNIDADES CAMPANHA','UNIDADES VENDIDAS'.\n",
      "* MDTR_UND pode ser também 'UNIDADES MDTR', 'MDTR_UNIDADES', 'MDTR'.\n",
      "\n",
      "* Caso o usuário já traga o nome da Marca, não se esqueça de adicionar o sulfixo ' (A4H)' caso ele não tenha escrito.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m<think>\n",
      "</think>\n",
      "\n",
      "Thought: Agora que sei as colunas, posso escrever uma consulta SQL para somar as unidades CPV por marca e encontrar a marca com o maior total.\n",
      "Action: sql_documentos\n",
      "Action Input: SELECT MARCA, SUM(CPV_UND) AS TOTAL_CPV FROM df_info_dataset GROUP BY MARCA ORDER BY TOTAL_CPV DESC LIMIT 1\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m         MARCA  TOTAL_CPV\n",
      "ARTRINAX (A4H)     541074\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m<think>\n",
      "</think>\n",
      "\n",
      "Final Answer: A marca que mais vendeu, considerando o total de unidades CPV, foi a **ARTRINAX (A4H)**, com um total de **541.074 unidades vendidas**.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Resposta: A marca que mais vendeu, considerando o total de unidades CPV, foi a **ARTRINAX (A4H)**, com um total de **541.074 unidades vendidas**.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Teste 2: Pergunta de cálculo ---\")\n",
    "user_input_2 = \"Considerando o total de unidades CPV, qual foi a marca que mais vendeu?\"\n",
    "response_2 = agent_executor.invoke({\"input\": user_input_2, \"chat_history\": chat_history})\n",
    "chat_history.extend([HumanMessage(content=user_input_2), AIMessage(content=response_2[\"output\"])])\n",
    "print(f\"Resposta: {response_2['output']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "074e4bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Teste 3: Pergunta sobre documentos ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m<think>\n",
      "Okay, let's tackle this question: \"Qual a terceira maior marca vendido em maio de 2024?\" which translates to \"What is the third largest brand sold in May 2024?\" \n",
      "\n",
      "First, I need to understand the data structure and the business rules. The user is asking about sales by brand in a specific month and year. The tools available are 'buscar_documentos' for initial understanding and 'sql_documentos' for querying the dataset. \n",
      "\n",
      "Since the user is asking for the third largest brand, I need to know how the data is structured. The 'df_info_dataset' is the dataset in question. The first step is to use 'buscar_documentos' to get an overview of the data. Maybe the dataset has columns like 'marca' (brand), 'mes' (month), 'ano' (year), and 'quantidade_vendida' (sold quantity). \n",
      "\n",
      "So, I'll start by using 'buscar_documentos' with a query to understand the dataset's structure and the relevant fields. The query could be something like \"Explique o dataset df_info_dataset e suas principais colunas relacionadas a vendas de marcas.\" \n",
      "\n",
      "Once I get the structure, I can proceed to write an SQL query to calculate the total sales per brand in May 2024, sort them in descending order, and pick the third one. The SQL query would need to filter by month and year, sum the quantities, order by descending, and then limit to the third row. \n",
      "\n",
      "Wait, but the user might have different columns. Let me make sure. For example, if the dataset has 'marca', 'mes', 'ano', and 'quantidade_vendida', then the SQL would be:\n",
      "\n",
      "SELECT marca, SUM(quantidade_vendida) AS total_vendas\n",
      "FROM df_info_dataset\n",
      "WHERE mes = 'maio' AND ano = 2024\n",
      "GROUP BY marca\n",
      "ORDER BY total_vendas DESC\n",
      "LIMIT 1 OFFSET 2;\n",
      "\n",
      "But I need to confirm the exact column names and the way the data is stored. So first, using 'buscar_documentos' to get the structure is crucial. Let's proceed with that.\n",
      "</think>\n",
      "\n",
      "Thought: Preciso entender a estrutura do dataset e as regras de negócio para identificar as vendas por marca em maio de 2024. Começarei usando a ferramenta buscar_documentos para obter informações sobre o dataset.\n",
      "\n",
      "Action: buscar_documentos\n",
      "Action Input: Explique o dataset df_info_dataset e suas principais colunas relacionadas a vendas de marcas.\n",
      "\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m**EXEMPLO_3 CONVERSÃO, o usuário pode pedir a conversão de algum produto, esta regra consiste na soma de CPV_UND dividido pela soma de MDTR_UND, deve-se seguir o exemplo da estrutura abaixo e alterando as variáveis conforme necessidade:\n",
      "select sum(CPV_UND) / sum(MDTR_UND)\n",
      "from df_info_dataset\n",
      "group by Marca\n",
      "\n",
      "**EXEMPLO_4 TOTAL DE MARCAS, o usuário pode pedir o total de marcas distintas de algum produto, esta regra consiste na contagem distinta das marcas , deve-se seguir o exemplo da estrutura abaixo e alterando as variáveis conforme necessidade:\n",
      "select count(distinct(Marca))\n",
      "from df_info_dataset\n",
      "group by Marca\n",
      "\n",
      "\n",
      "3) ESTRUTURA DO DATASET, TERMOS & SINÔNIMOS do dataset 'df_info_dataset':\n",
      "* 'DATA': Tipo data (yyyy-mm-dd).\n",
      "* 'MARCA': Tipo texto (ex: 'LUTEAL (A4H)').\n",
      "* 'APRESENTACAO': Tipo texto (ex: 'LUTEAL CAP MOLE BLX60').\n",
      "* 'EAN': Tipo texto/numérico (código, ex: '7896658040894').\n",
      "* 'MDTR_UND': Tipo numérico (Unidades de MDTR).\n",
      "* 'CPV_UND': Tipo numérico (Unidades de CPV).\n",
      "\n",
      "* **EXEMPLO ERRADO DE FILTRO DE DATA:** `WHERE year(DATA) = 2024 AND month(DATA) = 5`\n",
      "\n",
      "\n",
      "2) REGRAS DE NEGOCIO\n",
      "**EXEMPLO_1 SOMA, o usuário pode pedir o valor total de uma marca então deve-se utilizar a ferramenta adequada para query, seguindo o exemplo da estrutura abaixo e alterando as variáveis conforme necessidade:\n",
      "select sum(CPV_UND) \n",
      "from df_info_dataset\n",
      "where Marca = 'MOTORE (A4H)'\n",
      "\n",
      "**EXEMPLO_2 MÉDIA, o usuário pode pedir a média de  períodos então deve-se utilizar a ferramenta adequada para query, seguindo o exemplo da estrutura abaixo e alterando as variáveis conforme necessidade:\n",
      "select avg(CPV_UND) \n",
      "from df_info_dataset\n",
      "where Data >= '2024-01-01' and Data <= '2024-12-31' and Marca = 'ALENIA (A4H)'\n",
      "\n",
      "**Sinônimos e Definições Adicionais:**\n",
      "* Marca pode ser também 'Produto'.\n",
      "* Data pode ser também 'Período, Data ou Ocorrência'.\n",
      "* Apresentacao pode ser também 'SKU'.\n",
      "* EAN pode ser também 'Código'.\n",
      "* CPV_UND pode ser também 'UNIDADES CPV','CPV_UNIDADES','UND_CAMPANHA','UNIDADES CAMPANHA','UNIDADES VENDIDAS'.\n",
      "* MDTR_UND pode ser também 'UNIDADES MDTR', 'MDTR_UNIDADES', 'MDTR'.\n",
      "\n",
      "* Caso o usuário já traga o nome da Marca, não se esqueça de adicionar o sulfixo ' (A4H)' caso ele não tenha escrito.\n",
      "\n",
      "1) REGRAS DE SINTAXE \n",
      " **NÃO INCLUA ASPAS TRIPLAS (```) OU QUALQUER OUTRO DELIMITADOR DE CÓDIGO NO Action Input para 'query_tool'.**\n",
      " **EXEMPLO CERTO:** Action Input: SELECT MARCA, SUM(CPV_UND) FROM df_info_dataset GROUP BY MARCA\n",
      " **EXEMPLO ERRADO:** Action Input: ```SELECT MARCA, SUM(CPV_UND) FROM df_info_dataset GROUP BY MARCA```\n",
      "                  \n",
      " **Regras Específicas para Filtros de Data:**\n",
      " * Ao filtrar por datas, **SEMPRE** utilize o formato `WHERE DATA >= 'YYYY-MM-DD' AND DATA <= 'YYYY-MM-DD'`.\n",
      " * **NUNCA** utilize funções como `year(DATA) = YYYY` ou `month(DATA) = MM` ou qualquer outro método que não seja a comparação direta de datas no formato 'YYYY-MM-DD'.\n",
      " * **EXEMPLO CERTO DE FILTRO DE DATA:** `WHERE DATA >='2025-05-01' AND DATA <= '2024-05-31'` \n",
      "\n",
      " * **EXEMPLO ERRADO DE FILTRO DE DATA:** `WHERE year(DATA) = 2024 AND month(DATA) = 5`\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m<think>\n",
      "</think>\n",
      "\n",
      "Agora que sei a estrutura do dataset e as regras de negócio, posso formular a query SQL para encontrar a terceira maior marca vendida em maio de 2024. \n",
      "\n",
      "Action: sql_documentos\n",
      "Action Input: SELECT MARCA, SUM(CPV_UND) AS TOTAL_VENDAS FROM df_info_dataset WHERE DATA >= '2024-05-01' AND DATA <= '2024-05-31' GROUP BY MARCA ORDER BY TOTAL_VENDAS DESC LIMIT 1 OFFSET 2;\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m         MARCA  TOTAL_VENDAS\n",
      "DORMAVIX (A4H)         14655\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m<think>\n",
      "</think>\n",
      "\n",
      "Final Answer: A terceira maior marca vendida em maio de 2024 foi a **DORMAVIX (A4H)**, com um total de 14.655 unidades vendidas.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Resposta: A terceira maior marca vendida em maio de 2024 foi a **DORMAVIX (A4H)**, com um total de 14.655 unidades vendidas.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Teste 3: Pergunta sobre documentos ---\")\n",
    "user_input_3 = \"Qual a terceira maior marca vendido em maio de 2024?\"\n",
    "response_3 = agent_executor.invoke({\"input\": user_input_3, \"chat_history\": chat_history})\n",
    "chat_history.extend([HumanMessage(content=user_input_3), AIMessage(content=response_3[\"output\"])])\n",
    "print(f\"Resposta: {response_3['output']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "888409b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Teste 4: Outra pergunta sobre documentos ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m<think>\n",
      "Okay, the user is asking for the conversion of the brand NUBERON in August 2024. First, I need to understand what exactly they mean by \"conversão.\" In business terms, this could refer to sales conversion, maybe the number of units sold, revenue generated, or some other metric. Since the user mentioned \"Marca NUBERON,\" I should check if there's specific data related to this brand in the dataset.\n",
      "\n",
      "I should start by using the buscar_documentos tool to get an understanding of the data related to NUBERON and the conversion metric. The query should be in natural language to explain what I'm looking for. Let me input that.\n",
      "\n",
      "Action: buscar_documentos\n",
      "Action Input: \"Informações sobre a marca NUBERON e a conversão em agosto de 2024\"\n",
      "\n",
      "After getting the response, I can then use the sql_documentos tool to run a specific query on the dataset to retrieve the exact figures. The response from buscar_documentos might give me the necessary context to form the correct SQL query. For example, if \"conversão\" refers to sales, I might need to sum the sales for NUBERON in August 2024. I need to make sure the SQL query is correctly structured with the right columns and filters.\n",
      "</think>\n",
      "\n",
      "Thought: Preciso entender o contexto da palavra \"conversão\" em relação à marca NUBERON e ao mês de agosto de 2024. Utilizarei a ferramenta `buscar_documentos` para obter informações sobre o significado dessa métrica no dataset.\n",
      "\n",
      "Action: buscar_documentos  \n",
      "Action Input: \"Definição de 'conversão' para a marca NUBERON e dados relacionados a agosto de 2024\"  \n",
      "\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m1) REGRAS DE SINTAXE \n",
      " **NÃO INCLUA ASPAS TRIPLAS (```) OU QUALQUER OUTRO DELIMITADOR DE CÓDIGO NO Action Input para 'query_tool'.**\n",
      " **EXEMPLO CERTO:** Action Input: SELECT MARCA, SUM(CPV_UND) FROM df_info_dataset GROUP BY MARCA\n",
      " **EXEMPLO ERRADO:** Action Input: ```SELECT MARCA, SUM(CPV_UND) FROM df_info_dataset GROUP BY MARCA```\n",
      "                  \n",
      " **Regras Específicas para Filtros de Data:**\n",
      " * Ao filtrar por datas, **SEMPRE** utilize o formato `WHERE DATA >= 'YYYY-MM-DD' AND DATA <= 'YYYY-MM-DD'`.\n",
      " * **NUNCA** utilize funções como `year(DATA) = YYYY` ou `month(DATA) = MM` ou qualquer outro método que não seja a comparação direta de datas no formato 'YYYY-MM-DD'.\n",
      " * **EXEMPLO CERTO DE FILTRO DE DATA:** `WHERE DATA >='2025-05-01' AND DATA <= '2024-05-31'` \n",
      "\n",
      " * **EXEMPLO ERRADO DE FILTRO DE DATA:** `WHERE year(DATA) = 2024 AND month(DATA) = 5`\n",
      "\n",
      "* **EXEMPLO ERRADO DE FILTRO DE DATA:** `WHERE year(DATA) = 2024 AND month(DATA) = 5`\n",
      "\n",
      "\n",
      "2) REGRAS DE NEGOCIO\n",
      "**EXEMPLO_1 SOMA, o usuário pode pedir o valor total de uma marca então deve-se utilizar a ferramenta adequada para query, seguindo o exemplo da estrutura abaixo e alterando as variáveis conforme necessidade:\n",
      "select sum(CPV_UND) \n",
      "from df_info_dataset\n",
      "where Marca = 'MOTORE (A4H)'\n",
      "\n",
      "**EXEMPLO_2 MÉDIA, o usuário pode pedir a média de  períodos então deve-se utilizar a ferramenta adequada para query, seguindo o exemplo da estrutura abaixo e alterando as variáveis conforme necessidade:\n",
      "select avg(CPV_UND) \n",
      "from df_info_dataset\n",
      "where Data >= '2024-01-01' and Data <= '2024-12-31' and Marca = 'ALENIA (A4H)'\n",
      "\n",
      "**EXEMPLO_3 CONVERSÃO, o usuário pode pedir a conversão de algum produto, esta regra consiste na soma de CPV_UND dividido pela soma de MDTR_UND, deve-se seguir o exemplo da estrutura abaixo e alterando as variáveis conforme necessidade:\n",
      "select sum(CPV_UND) / sum(MDTR_UND)\n",
      "from df_info_dataset\n",
      "group by Marca\n",
      "\n",
      "**EXEMPLO_4 TOTAL DE MARCAS, o usuário pode pedir o total de marcas distintas de algum produto, esta regra consiste na contagem distinta das marcas , deve-se seguir o exemplo da estrutura abaixo e alterando as variáveis conforme necessidade:\n",
      "select count(distinct(Marca))\n",
      "from df_info_dataset\n",
      "group by Marca\n",
      "\n",
      "\n",
      "3) ESTRUTURA DO DATASET, TERMOS & SINÔNIMOS do dataset 'df_info_dataset':\n",
      "* 'DATA': Tipo data (yyyy-mm-dd).\n",
      "* 'MARCA': Tipo texto (ex: 'LUTEAL (A4H)').\n",
      "* 'APRESENTACAO': Tipo texto (ex: 'LUTEAL CAP MOLE BLX60').\n",
      "* 'EAN': Tipo texto/numérico (código, ex: '7896658040894').\n",
      "* 'MDTR_UND': Tipo numérico (Unidades de MDTR).\n",
      "* 'CPV_UND': Tipo numérico (Unidades de CPV).\n",
      "\n",
      "**Sinônimos e Definições Adicionais:**\n",
      "* Marca pode ser também 'Produto'.\n",
      "* Data pode ser também 'Período, Data ou Ocorrência'.\n",
      "* Apresentacao pode ser também 'SKU'.\n",
      "* EAN pode ser também 'Código'.\n",
      "* CPV_UND pode ser também 'UNIDADES CPV','CPV_UNIDADES','UND_CAMPANHA','UNIDADES CAMPANHA','UNIDADES VENDIDAS'.\n",
      "* MDTR_UND pode ser também 'UNIDADES MDTR', 'MDTR_UNIDADES', 'MDTR'.\n",
      "\n",
      "* Caso o usuário já traga o nome da Marca, não se esqueça de adicionar o sulfixo ' (A4H)' caso ele não tenha escrito.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m<think>\n",
      "</think>\n",
      "\n",
      "A conversão da marca NUBERON em agosto de 2024 pode ser calculada como a soma das unidades de CPV dividida pela soma das unidades de MDTR para essa marca no mês especificado. Vou utilizar a ferramenta `sql_documentos` para executar a consulta com base nas regras de negócio definidas.\n",
      "\n",
      "Action: sql_documentos  \n",
      "Action Input:  \n",
      "SELECT  \n",
      "    SUM(CPV_UND) / SUM(MDTR_UND) AS Conversao  \n",
      "FROM  \n",
      "    df_info_dataset  \n",
      "WHERE  \n",
      "    MARCA = 'NUBERON (A4H)'  \n",
      "    AND DATA >= '2024-08-01'  \n",
      "    AND DATA <= '2024-08-31'\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m0.025495750708215296\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m<think>\n",
      "</think>\n",
      "\n",
      "Final Answer: A conversão da marca NUBERON em agosto de 2024 foi de aproximadamente **0,0255** (ou 2,55%).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Resposta: A conversão da marca NUBERON em agosto de 2024 foi de aproximadamente **0,0255** (ou 2,55%).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Teste 4: Outra pergunta sobre documentos ---\")\n",
    "user_input_4 = \"Me diga a conversão da Marca NUBERON em agosto de 2024\"\n",
    "response_4 = agent_executor.invoke({\"input\": user_input_4, \"chat_history\": chat_history})\n",
    "chat_history.extend([HumanMessage(content=user_input_4), AIMessage(content=response_4[\"output\"])])\n",
    "print(f\"Resposta: {response_4['output']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
