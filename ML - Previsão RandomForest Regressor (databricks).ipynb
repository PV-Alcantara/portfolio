{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45a17ae0-7450-45ef-91d0-71eece2fdb31",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Criação do Dataset"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": null
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "create or replace temp view prev as(\n",
    "select \n",
    "date_format(f.DATA_COMPRA,'yyyy-MM') as ANOMES\n",
    ",sum(f.QUANTIDADE) as UND\n",
    "from dmn_transformacao_digital_dev.db_analytics.cpv_fvendas as f\n",
    "left join dmn_transformacao_digital_dev.db_analytics.cpv_dprodutos as dp on dp.ID_PRODUTO = f.ID_PRODUTO\n",
    "left join dmn_transformacao_digital_dev.db_analytics.cpv_dpdv as dl on dl.ID_LOJA = f.ID_LOJA\n",
    "Where dl.GRUPO = \"DPSP\" and f.DATA_COMPRA >= \"2021-01-01\" and f.DATA_COMPRA <= \"2025-02-28\"\n",
    "group by all\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c47a0cf-6e8e-4549-9d32-e367564b15ed",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Instalação de App"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5bed5667-4512-4221-b675-be3869668659/lib/python3.10/site-packages (25.1)\r\nRequirement already satisfied: python-slugify in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (8.0.4)\r\nRequirement already satisfied: loguru in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (0.7.3)\r\nRequirement already satisfied: openpyxl in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (3.1.5)\r\nRequirement already satisfied: scikit-learn in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (1.3.2)\r\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.10/site-packages (1.2.0)\r\nRequirement already satisfied: shap in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (0.47.2)\r\nRequirement already satisfied: imbalanced-learn in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5bed5667-4512-4221-b675-be3869668659/lib/python3.10/site-packages (0.13.0)\r\nRequirement already satisfied: text-unidecode>=1.3 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (from python-slugify) (1.3)\r\nRequirement already satisfied: et-xmlfile in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (from openpyxl) (2.0.0)\r\nRequirement already satisfied: numpy<2.0,>=1.17.3 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (from scikit-learn) (1.24.4)\r\nRequirement already satisfied: scipy>=1.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5bed5667-4512-4221-b675-be3869668659/lib/python3.10/site-packages (from scikit-learn) (1.15.2)\r\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn) (2.2.0)\r\nRequirement already satisfied: pandas in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (from shap) (2.2.3)\r\nRequirement already satisfied: tqdm>=4.27.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (from shap) (4.67.1)\r\nRequirement already satisfied: packaging>20.9 in /databricks/python3/lib/python3.10/site-packages (from shap) (21.3)\r\nRequirement already satisfied: slicer==0.0.8 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (from shap) (0.0.8)\r\nRequirement already satisfied: numba>=0.54 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (from shap) (0.61.2)\r\nRequirement already satisfied: cloudpickle in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (from shap) (3.1.1)\r\nRequirement already satisfied: typing-extensions in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (from shap) (4.13.2)\r\nRequirement already satisfied: sklearn-compat<1,>=0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5bed5667-4512-4221-b675-be3869668659/lib/python3.10/site-packages (from imbalanced-learn) (0.1.3)\r\nRequirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (from numba>=0.54->shap) (0.44.0)\r\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /databricks/python3/lib/python3.10/site-packages (from packaging>20.9->shap) (3.0.9)\r\nRequirement already satisfied: python-dateutil>=2.8.2 in /databricks/python3/lib/python3.10/site-packages (from pandas->shap) (2.8.2)\r\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.10/site-packages (from pandas->shap) (2022.1)\r\nRequirement already satisfied: tzdata>=2022.7 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (from pandas->shap) (2025.2)\r\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install python-slugify loguru openpyxl scikit-learn joblib shap imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ed53ecd-3d4c-4f58-9419-29402ef8c6bd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Bibliotecas"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fc11bb9-fa65-47fd-82e5-79ae3a855d68",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Definição de funções"
    }
   },
   "outputs": [],
   "source": [
    "# Função para pré-processar os dados\n",
    "def preprocess_data(df):\n",
    "    logger.info(\"Iniciando pré-processamento...\")\n",
    "    df = df.sort_values('ANOMES').reset_index(drop=True)\n",
    "    df = df.dropna().copy()  # Garante que não altera a versão original por acidente\n",
    "    if 'MES_SEQ' not in df.columns:\n",
    "        df['MES_SEQ'] = np.arange(len(df))\n",
    "    else:\n",
    "        logger.warning(\"'MES_SEQ' já existia! Substituindo valores.\")\n",
    "        df['MES_SEQ'] = np.arange(len(df))\n",
    "    return df\n",
    "  \n",
    "\n",
    "# Função para treinar o modelo reg linear\n",
    "def train_model(X, Y):\n",
    "    logger.info(\"Treinando modelo...\")\n",
    "    rl = LinearRegression()\n",
    "    rl.fit(X,Y)\n",
    "    logger.success(\"Modelo treinado.\")\n",
    "    return rl\n",
    "\n",
    "# Função para treinar o modelo Random Forest\n",
    "def train_random_forest_model(X, Y):\n",
    "    logger.info(\"Treinando modelo Random Forest...\")\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=300,  # Número de árvores\n",
    "        max_depth=10,    # Deixa as árvores crescerem até necessário\n",
    "        random_state=42,    # Para resultados reproduzíveis\n",
    "        max_features= 'sqrt',\n",
    "        min_samples_leaf =1,\n",
    "        min_samples_split=2\n",
    "        \n",
    "    )\n",
    "    rf.fit(X, Y)\n",
    "    logger.success(\"Modelo Random Forest treinado.\")\n",
    "    return rf\n",
    "\n",
    "# Função do previsor\n",
    "def previsor(modelo, df):\n",
    "    logger.info(\"calculando a previsão...\")\n",
    "    p = df['MES_SEQ'].max() + 1\n",
    "    X_NOVO = np.array([[p]])\n",
    "    Y_NOVO = modelo.predict(X_NOVO)\n",
    "\n",
    "\n",
    "    logger.success(f\"Previsao: {Y_NOVO}\")\n",
    "    \n",
    "    return Y_NOVO\n",
    "\n",
    "# Função para avaliar o modelo\n",
    "def avaliar_modelo(modelo, df):\n",
    "    logger.info(\"Avaliando modelo...\")\n",
    "    \n",
    "    \n",
    "    X = df['MES_SEQ'].values.reshape(-1, 1)\n",
    "    y_true = df['UND']\n",
    "    y_pred = modelo.predict(X)\n",
    "\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    logger.success(f\"Avaliação concluída. R²: {r2:.4f} | MAE: {mae:.2f}\")\n",
    "  \n",
    "    return r2, mae\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c034ebb-dcf7-4d41-96be-45fa415aebcd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Execução"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-04-29 14:41:18.964\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mpreprocess_data\u001B[0m:\u001B[36m3\u001B[0m - \u001B[1mIniciando pré-processamento...\u001B[0m\n\u001B[32m2025-04-29 14:41:18.968\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mtrain_random_forest_model\u001B[0m:\u001B[36m24\u001B[0m - \u001B[1mTreinando modelo Random Forest...\u001B[0m\n\u001B[32m2025-04-29 14:41:19.353\u001B[0m | \u001B[32m\u001B[1mSUCCESS \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mtrain_random_forest_model\u001B[0m:\u001B[36m35\u001B[0m - \u001B[32m\u001B[1mModelo Random Forest treinado.\u001B[0m\n\u001B[32m2025-04-29 14:41:19.355\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mprevisor\u001B[0m:\u001B[36m40\u001B[0m - \u001B[1mcalculando a previsão...\u001B[0m\n\u001B[32m2025-04-29 14:41:19.382\u001B[0m | \u001B[32m\u001B[1mSUCCESS \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mprevisor\u001B[0m:\u001B[36m46\u001B[0m - \u001B[32m\u001B[1mPrevisao: [87752.97]\u001B[0m\n\u001B[32m2025-04-29 14:41:19.383\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mavaliar_modelo\u001B[0m:\u001B[36m52\u001B[0m - \u001B[1mAvaliando modelo...\u001B[0m\n\u001B[32m2025-04-29 14:41:19.412\u001B[0m | \u001B[32m\u001B[1mSUCCESS \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mavaliar_modelo\u001B[0m:\u001B[36m62\u001B[0m - \u001B[32m\u001B[1mAvaliação concluída. R²: 0.9389 | MAE: 3934.31\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# Pipeline de execução: Leitura, treino, validação, avaliação e salvamento\n",
    "\n",
    "# 1. Ler os dados\n",
    "aprendizagem = spark.table(\"prev\").toPandas()\n",
    "\n",
    "# 2. Pre-tratamento\n",
    "aprendizagem = preprocess_data(aprendizagem)\n",
    "\n",
    "# 3. Treinar o modelo\n",
    "modelo_rf = train_random_forest_model(\n",
    "    aprendizagem['MES_SEQ'].values.reshape(-1, 1), \n",
    "    aprendizagem['UND']\n",
    ")\n",
    "\n",
    "# 4. criar a previsão\n",
    "previsao = previsor(modelo_rf, aprendizagem)\n",
    "\n",
    "#5. Avalaiação do modelo\n",
    "nota = avaliar_modelo(modelo_rf,aprendizagem)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "552c6a69-e765-4d17-8a31-df97917825ee",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "GridSearch responde qual a melhor configuração do Randomforest"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define o modelo base\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Define o grid de hiperparâmetros para testar\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # número de árvores\n",
    "    'max_depth': [5, 10, 15, None],   # profundidade máxima\n",
    "    'min_samples_split': [2, 5, 10],  # mínimo para dividir\n",
    "    'min_samples_leaf': [1, 2, 4],    # mínimo em folha\n",
    "    'max_features': ['auto', 'sqrt']  # número de variáveis\n",
    "}\n",
    "\n",
    "# Configura o GridSearch\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,   # 5-fold cross validation\n",
    "    scoring='neg_mean_absolute_error',  # queremos minimizar o erro absoluto\n",
    "    n_jobs=-1,  # usa todos os núcleos da CPU\n",
    "    verbose=2   # mostra o progresso\n",
    ")\n",
    "\n",
    "# Prepara os dados\n",
    "X = aprendizagem['MES_SEQ'].values.reshape(-1, 1)\n",
    "y = aprendizagem['UND']\n",
    "\n",
    "# Roda a busca\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Melhor modelo encontrado\n",
    "melhor_modelo = grid_search.best_estimator_\n",
    "\n",
    "print(\"Melhores hiperparâmetros encontrados:\")\n",
    "print(grid_search.best_params_)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8677219756460503,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "ML - Previsão RandomForest Regressor",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}